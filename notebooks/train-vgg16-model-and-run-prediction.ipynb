{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99e1527-ddd8-4ddc-b2b6-b1405aaa8c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kaggle\n",
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b970f5a-35ba-4851-89eb-7c19e4ff6ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43b447cd-eb2d-4788-9993-9cf4dff343c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/benjaminwarner/resized-2015-2019-blindness-detection-images\n"
     ]
    }
   ],
   "source": [
    "# Download Datasets\n",
    "\n",
    "import os\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "raw_data_directory = 'data/raw/'\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "    \n",
    "api.dataset_download_files('benjaminwarner/resized-2015-2019-blindness-detection-images', path=raw_data_directory, unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c861fb43-e54f-4a53-8dc2-139def035e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      "resizedtest15\n",
      "resizedtrain15\n",
      "resizedtrain19\n",
      ".ipynb_checkpoints\n",
      "resizedtest19\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(raw_data_directory):\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "949c44fd-e533-49e0-8e90-13a39f6eddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove spaces from raw data directories\n",
    "for filename in os.listdir(raw_data_directory):\n",
    "    old_file = os.path.join(raw_data_directory, filename)\n",
    "        \n",
    "    # Check if it is a file and has spaces in the name\n",
    "    if os.path.isfile(old_file) and \" \" in filename:\n",
    "        new_filename = filename.replace(\" \", replace_with)\n",
    "        new_file = os.path.join(raw_data_directory, new_filename)\n",
    "            \n",
    "        # Rename the file if the name has changed\n",
    "        if old_file != new_file:\n",
    "            os.rename(old_file, new_file)\n",
    "            print(f\"Renamed: {old_file} -> {new_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10fe31f3-ddbc-4b12-9992-e3892932490a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id_code': '000c1434d8d7', 'diagnosis': 2},\n",
       " {'id_code': '001639a390f0', 'diagnosis': 4},\n",
       " {'id_code': '0024cdab0c1e', 'diagnosis': 1},\n",
       " {'id_code': '002c21358ce6', 'diagnosis': 0},\n",
       " {'id_code': '005b95c28852', 'diagnosis': 0},\n",
       " {'id_code': '0083ee8054ee', 'diagnosis': 4},\n",
       " {'id_code': '0097f532ac9f', 'diagnosis': 0},\n",
       " {'id_code': '00a8624548a9', 'diagnosis': 2},\n",
       " {'id_code': '00b74780d31d', 'diagnosis': 2},\n",
       " {'id_code': '00cb6555d108', 'diagnosis': 1}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "dataset_path = \"data/raw/labels/trainLabels19.csv\"\n",
    "json_data = 'data/data.json'\n",
    "\n",
    "if not os.path.exists(json_data):\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    df.head()\n",
    "\n",
    "    json_data = df.to_json(orient='records', indent=4)\n",
    "\n",
    "    with open('data/data.json', 'w') as f:\n",
    "        f.write(json_data)\n",
    "        \n",
    "with open(json_data, 'r', encoding='utf-8') as f:\n",
    "        data_as_dict = json.load(f)\n",
    "\n",
    "print(type(data_as_dict))\n",
    "data_as_dict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e8a28a-5ac2-4a62-9bcc-b0248c34255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = 224  # VGG16 expects 224x224 input\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Prepare Data - Copy Images to Class-Specific Directories\n",
    "def prepare_data(data, src_folder, dst_folder):\n",
    "    if not os.path.exists(dst_folder):\n",
    "        os.makedirs(dst_folder)\n",
    "    \n",
    "    for record in data:\n",
    "        diagnosis = str(record['diagnosis'])\n",
    "        img_name = f\"{record['id_code']}.jpg\"\n",
    "        \n",
    "        class_folder = os.path.join(dst_folder, diagnosis)\n",
    "        if not os.path.exists(class_folder):\n",
    "            os.makedirs(class_folder)\n",
    "        \n",
    "        shutil.copy(os.path.join(src_folder, img_name), os.path.join(class_folder, img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fea74e48-44b5-45b9-9fc7-661d6b475374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labels data and rearrange images in directories\n",
    "with open(json_data, 'r', encoding='utf-8') as f:\n",
    "    data_as_dict = json.load(f)\n",
    "\n",
    "# dataset = [{'id_code': '000c1434d8d7', 'diagnosis': 2}, {'id_code': '001639a390f0', 'diagnosis': 4}]\n",
    "prepare_data(data_as_dict, src_folder='data/raw/resizedtrain19', dst_folder='data/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0487ee0f-fcd0-4b8a-835f-65c3a2f0534e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2932 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Image Data Generators for Augmentation and Preprocessing\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'data/train',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "334138e0-c3ea-4eed-870c-957eccff52b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 732 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = train_datagen.flow_from_directory(\n",
    "    'data/train',\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "262cf9a8-f2d1-43fe-b7c1-55580e77751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pre-Trained VGG16 Model + Modify it\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "879b2a27-bdf4-4047-a29f-ddd8d72b57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze VGG16 Layers to Use as Feature Extractor\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build the Model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(5, activation='softmax')  # 5 classes (0-4 diagnosis)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5321494b-ab3f-4e41-bf08-2c573846a73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "92/92 [==============================] - 144s 2s/step - loss: 1.2455 - accuracy: 0.6197 - val_loss: 0.8122 - val_accuracy: 0.7077\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 143s 2s/step - loss: 0.9448 - accuracy: 0.6852 - val_loss: 0.8295 - val_accuracy: 0.7090\n",
      "Epoch 3/10\n",
      "92/92 [==============================] - 144s 2s/step - loss: 0.9659 - accuracy: 0.6828 - val_loss: 0.7849 - val_accuracy: 0.7145\n",
      "Epoch 4/10\n",
      "92/92 [==============================] - 143s 2s/step - loss: 0.9285 - accuracy: 0.6849 - val_loss: 0.7936 - val_accuracy: 0.7199\n",
      "Epoch 5/10\n",
      "92/92 [==============================] - 143s 2s/step - loss: 0.9330 - accuracy: 0.6746 - val_loss: 0.8282 - val_accuracy: 0.7213\n",
      "Epoch 6/10\n",
      "92/92 [==============================] - 144s 2s/step - loss: 0.8858 - accuracy: 0.6951 - val_loss: 0.8059 - val_accuracy: 0.7213\n",
      "Epoch 7/10\n",
      "92/92 [==============================] - 144s 2s/step - loss: 0.8744 - accuracy: 0.7060 - val_loss: 0.7728 - val_accuracy: 0.7227\n",
      "Epoch 8/10\n",
      "92/92 [==============================] - 143s 2s/step - loss: 0.8417 - accuracy: 0.7094 - val_loss: 0.7682 - val_accuracy: 0.7240\n",
      "Epoch 9/10\n",
      "92/92 [==============================] - 143s 2s/step - loss: 0.8437 - accuracy: 0.7070 - val_loss: 0.7866 - val_accuracy: 0.7158\n",
      "Epoch 10/10\n",
      "92/92 [==============================] - 143s 2s/step - loss: 0.8094 - accuracy: 0.7145 - val_loss: 0.7424 - val_accuracy: 0.7254\n"
     ]
    }
   ],
   "source": [
    "# Compile the Model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the Model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fa909fcb-a88a-4de5-936b-e7cedc055e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 29s 1s/step - loss: 0.7424 - accuracy: 0.7254\n",
      "Validation Accuracy: 72.54%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "val_loss, val_accuracy = model.evaluate(val_generator)\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "759d26f5-e202-46f8-8138-9a3a0ae0014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new model\n",
    "# Model Version should be updated on every save\n",
    "\n",
    "model.save('models/v1.0_vgg16_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebc5246-d4f0-4d66-8818-f8d3d83385df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Model\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('models/final_vgg16_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55796aa9-b6b8-4b1d-ba6c-37a8614c321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_path = 'data/predictions/081c7ec32f27.jpg'\n",
    "img = load_img(img_path, target_size=(224, 224))  # Resize to 224x224\n",
    "img_array = img_to_array(img) / 255.0  # Rescale pixel values\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "\n",
    "# Predict the diagnosis\n",
    "prediction = model.predict(img_array)\n",
    "\n",
    "# Get the class with the highest probability\n",
    "predicted_class = np.argmax(prediction, axis=1)[0]\n",
    "print(f'Predicted diagnosis class: {predicted_class}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
